{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e108352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5d5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"INSERT INTO TABLE_NAME (COLUMNS) VALUES\\nDATA;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b794598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_item(i: Any):\n",
    "    if type(i) == str:\n",
    "        return f\"'{i}'\"\n",
    "    elif i == None:\n",
    "        return 'NULL'\n",
    "    return str(i)\n",
    "\n",
    "def transform_list(l: List):\n",
    "    return list(map(transform_item, l))\n",
    "\n",
    "def transform_list_to_str(l: List):\n",
    "    tmp = map(lambda l_: ', '.join(l_), l)\n",
    "    tmp = map(lambda x: f'({x})', tmp)\n",
    "    return ',\\n'.join(tmp)\n",
    "\n",
    "# print(transform_list_to_str([[\"'string'\", '2', '3.4'], [\"'string2'\", '3', '4.2']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9da09f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO ANIME (teste, a) VALUES\n",
      "(1, 'b'),\n",
      "(2, 'c');\n"
     ]
    }
   ],
   "source": [
    "def generate_insert_tuples(table_name: str, columns: List, values: List[List[Any]]):\n",
    "    insert = TEMPLATE.replace('TABLE_NAME', table_name)\n",
    "    \n",
    "    if len(columns) <= 0:\n",
    "        insert = insert.replace('(COLUMNS) ', '')\n",
    "    else:\n",
    "        insert = insert.replace('COLUMNS', ', '.join(columns))\n",
    "        \n",
    "    values_ = map(transform_list, values)\n",
    "    values_ = transform_list_to_str(values_)\n",
    "    \n",
    "    return insert.replace('DATA', values_)\n",
    "\n",
    "print(generate_insert_tuples('ANIME', ['teste', 'a'], [[1, 'b'], [2, 'c']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a65e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(df: 'pd.DataFrame', column):\n",
    "    values = set()\n",
    "    for i in df[column]:\n",
    "        for name in i.split(', '):\n",
    "            values.add(name)\n",
    "    return [[i] for i in list(values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca3fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_gen():\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        yield i\n",
    "\n",
    "def get_ids(data: List[List[Any]]):\n",
    "    id_ = id_gen()\n",
    "    return [[i[0], next(id_)] for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa4966a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(df, data, column):\n",
    "    data_dict = dict(data)\n",
    "    list_ = list()\n",
    "    pair = zip(df['MAL_ID'], df[column])\n",
    "    for anime_id, d in pair:\n",
    "        dl = d.split(', ')\n",
    "        for i in dl:\n",
    "            list_.append([anime_id, data_dict[i]])\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "df5fb734",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATE = {\n",
    "    'Spring': 'primavera',\n",
    "    'Winter': 'inverno',\n",
    "    'Summer': 'verao',\n",
    "    'Fall': 'outono'\n",
    "}\n",
    "def season_split(x):\n",
    "    s = x.split()\n",
    "    if len(s) < 2 or s[0] not in ('Spring', 'Summer', 'Winter', 'Fall'):\n",
    "        return None\n",
    "    else:\n",
    "        return TRANSLATE[s[0]]\n",
    "    \n",
    "def year_split(x):\n",
    "    y = x.split()\n",
    "    if len(y) < 2:\n",
    "        return None\n",
    "    else:\n",
    "        return y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03be028b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html folder',\n",
       " 'anime.csv',\n",
       " 'rating_complete.csv',\n",
       " 'anime_with_synopsis.csv',\n",
       " 'watching_status.csv',\n",
       " 'animelist.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('anime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5819728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('anime/anime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e48db803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Producers'] = df['Producers'].apply(lambda s: s.replace(\"'\", ' '))\n",
    "df['Licensors'] = df['Licensors'].apply(lambda s: s.replace(\"'\", ' '))\n",
    "df['Name'] = df['Name'].apply(lambda n: n.replace(\"'\", \" \"))\n",
    "df['Studios'] = df['Studios'].apply(lambda s: s.replace(\"'\", ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2399ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = get_ids(get_unique_values(df, 'Genres'))\n",
    "producers = get_ids(get_unique_values(df, 'Producers'))\n",
    "licensors = get_ids(get_unique_values(df, 'Licensors'))\n",
    "studios = get_ids(get_unique_values(df, 'Studios'))\n",
    "anime_genres = create_pairs(df, genres, 'Genres')\n",
    "anime_producers = create_pairs(df, producers, 'Producers')\n",
    "anime_licensors = create_pairs(df, licensors, 'Licensors')\n",
    "anime_studios = create_pairs(df, studios, 'Studios')\n",
    "\n",
    "data_ = [\n",
    "    ('GENERO', ['nome', 'id'], genres), \n",
    "    ('PRODUTOR', ['nome', 'id'], producers),\n",
    "    ('LICENCIADOR', ['nome', 'id'], licensors),\n",
    "    ('ESTUDIO', ['nome', 'id'], studios),\n",
    "    ('participa', ['anime', 'genero'], anime_genres),\n",
    "    ('produz', ['anime', 'produtor'], anime_producers), \n",
    "    ('licencia', ['anime', 'licenciador'], anime_licensors), \n",
    "    ('anima', ['anime', 'estudio'], anime_studios)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "679f37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = df\n",
    "dfa.drop(['Genres', 'Producers', 'Licensors', 'Studios'], axis=1, inplace=True)\n",
    "dfa.drop(['English name', 'Japanese name'], axis=1, inplace=True)\n",
    "dfa.drop(['Aired'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "270917db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['year'] = dfa['Premiered'].apply(year_split)\n",
    "dfa['season'] = dfa['Premiered'].apply(season_split)\n",
    "dfa.drop(['Premiered'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c3b1e0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['primavera', None, 'verao', 'outono', 'inverno'], dtype=object)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa['season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9e2dfcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['Score'] = dfa['Score'].replace(['Unknown'], 0)\n",
    "dfa['Type'] = dfa['Type'].replace(['Unknown'], None)\n",
    "dfa['Episodes'] = dfa['Episodes'].replace(['Unknown'], 0)\n",
    "dfa['Source'] = dfa['Source'].replace(['Unknown'], 'Other')\n",
    "dfa['Ranked'] = dfa['Ranked'].replace(['Unknown'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "731d5e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MAL_ID', 'Name', 'Score', 'Type', 'Episodes', 'Source', 'Duration',\n",
       "       'Rating', 'Ranked', 'Popularity', 'Members', 'Favorites', 'Watching',\n",
       "       'Completed', 'On-Hold', 'Dropped', 'Plan to Watch', 'Score-10',\n",
       "       'Score-9', 'Score-8', 'Score-7', 'Score-6', 'Score-5', 'Score-4',\n",
       "       'Score-3', 'Score-2', 'Score-1', 'year', 'season'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "291e6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    name = f'Score-{i}'\n",
    "    dfa[name] = dfa[name].replace(['Unknown'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "c8875ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.drop(['Duration'], axis=1, inplace=True)\n",
    "dfa.drop(['Rating'], axis=1, inplace=True)\n",
    "dfa.drop(['Watching', 'Completed', 'On-Hold', 'Dropped', 'Plan to Watch'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5243328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = ['id', 'nome', 'nota', 'tipo', 'num_episodios', 'material_original',\n",
    "                '`rank`', 'popularidade', 'num_membros', 'num_favoritos', 'num_nota10',\n",
    "                'num_nota9', 'num_nota8', 'num_nota7', 'num_nota6', 'num_nota5',\n",
    "                'num_nota4', 'num_nota3', 'num_nota2', 'num_nota1', 'ano', 'estacao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ee825e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(dfa.columns)\n",
    "animes_ = zip(*[dfa[i] for i in columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "36c1dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = [('ANIME', table_columns, animes_), *data_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "fc78c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = pd.read_csv('anime/watching_status.csv')\n",
    "l = zip(ws['status'], ws[' description'])\n",
    "# acompanhamento\n",
    "watching_status = [[i, j] for i, j in l]\n",
    "\n",
    "data_ = [('ACOMPANHAMENTO', ['id', 'description'], watching_status), *data_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f1d14efc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [279]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dfw \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manime/animelist.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m users \u001b[38;5;241m=\u001b[39m [[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dfw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1250\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1248\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1250\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# dfw = pd.read_csv('anime/animelist.csv')\n",
    "# users = [[i] for i in dfw['user_id'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "4048f6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'anime_id', 'rating', 'watching_status', 'watched_episodes'], dtype='object')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "781ad81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = set()\n",
    "    \n",
    "with open('anime/animelist.csv', 'r') as fd:\n",
    "    fd.readline()\n",
    "    for i in fd:\n",
    "        users.add(i.split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "10c8fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ = [[i] for i in users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "7e598e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = [('USUARIO', ['id'], users_), *data_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d8e16121",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('popula.sql', 'w+') as fd:\n",
    "    for i in data_:\n",
    "        fd.write(generate_insert_tuples(*i))\n",
    "        fd.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "07e962c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = open('popula.sql', 'w+')\n",
    "# out.write('INSERT INTO assiste (usuario, anime, nota, acompanhamento, num_episodios_assistidos) VALUES\\n')\n",
    "# with open('anime/animelist.csv', 'r') as fd:\n",
    "#     fd.readline()\n",
    "#     last = f'({fd.readline().strip()})'\n",
    "#     for i in fd:\n",
    "#         out.write(f'INSERT INTO assiste (usuario, anime, nota, acompanhamento, num_episodios_assistidos) VALUES {last};\\n')\n",
    "#         last = f'({i.strip()})'\n",
    "#     out.write(f'INSERT INTO assiste (usuario, anime, nota, acompanhamento, num_episodios_assistidos) VALUES {last};\\n')\n",
    "# out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "804190da",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('popula.sql', 'w+')\n",
    "out.write('INSERT INTO assiste (usuario, anime, nota, acompanhamento, num_episodios_assistidos) VALUES\\n')\n",
    "limit = 0\n",
    "with open('anime/animelist.csv', 'r') as fd:\n",
    "    fd.readline()\n",
    "    last = f'({fd.readline().strip()})'\n",
    "    for i in fd:\n",
    "        if limit > 500000:\n",
    "            break\n",
    "        out.write(f'{last},\\n')\n",
    "        last = f'({i.strip()})'\n",
    "        limit += 1\n",
    "    out.write(f'{last};\\n\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c5182d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 67, 9, 1, 1],\n",
       " [0, 6702, 7, 1, 4],\n",
       " [0, 242, 10, 1, 4],\n",
       " [0, 4898, 0, 1, 1],\n",
       " [0, 21, 10, 1, 0],\n",
       " [0, 24, 9, 1, 5],\n",
       " [0, 2104, 0, 1, 4],\n",
       " [0, 4722, 8, 1, 4],\n",
       " [0, 6098, 6, 1, 2],\n",
       " [0, 3125, 9, 1, 29],\n",
       " [0, 481, 10, 1, 79],\n",
       " [0, 68, 6, 2, 23],\n",
       " [0, 1689, 6, 2, 3],\n",
       " [0, 2913, 6, 2, 40],\n",
       " [0, 1250, 7, 2, 26],\n",
       " [0, 356, 9, 2, 24],\n",
       " [0, 121, 9, 2, 51],\n",
       " [0, 430, 9, 2, 1],\n",
       " [0, 1829, 7, 2, 1],\n",
       " [0, 1571, 10, 2, 25],\n",
       " [0, 578, 10, 2, 1],\n",
       " [0, 431, 8, 2, 1],\n",
       " [0, 2762, 9, 2, 24],\n",
       " [0, 570, 7, 2, 1],\n",
       " [0, 3418, 9, 2, 50],\n",
       " [0, 3010, 7, 2, 52],\n",
       " [0, 1004, 5, 2, 1],\n",
       " [0, 433, 6, 2, 1],\n",
       " [0, 600, 6, 2, 12],\n",
       " [0, 2034, 8, 2, 24],\n",
       " [0, 164, 8, 2, 1],\n",
       " [0, 4086, 6, 2, 51],\n",
       " [0, 457, 0, 2, 26],\n",
       " [0, 20, 0, 2, 220],\n",
       " [0, 1074, 0, 2, 1],\n",
       " [0, 761, 0, 2, 1],\n",
       " [0, 2248, 6, 2, 1],\n",
       " [0, 597, 0, 2, 1],\n",
       " [0, 1047, 6, 2, 1],\n",
       " [0, 459, 9, 2, 1],\n",
       " [0, 466, 7, 2, 1],\n",
       " [0, 2543, 7, 2, 52],\n",
       " [0, 419, 8, 2, 26],\n",
       " [0, 199, 8, 2, 1],\n",
       " [0, 169, 7, 2, 12],\n",
       " [0, 2547, 7, 2, 46],\n",
       " [0, 174, 4, 2, 24],\n",
       " [0, 448, 5, 2, 2],\n",
       " [0, 2236, 10, 2, 1],\n",
       " [0, 415, 10, 2, 1],\n",
       " [0, 1894, 7, 2, 1],\n",
       " [0, 269, 9, 3, 64],\n",
       " [0, 235, 10, 3, 0],\n",
       " [0, 71, 0, 3, 3],\n",
       " [0, 245, 0, 3, 11],\n",
       " [0, 134, 0, 3, 3],\n",
       " [0, 1887, 0, 3, 2],\n",
       " [0, 3457, 0, 3, 1],\n",
       " [0, 1535, 0, 4, 27],\n",
       " [0, 1726, 0, 4, 2],\n",
       " [0, 228, 0, 4, 3],\n",
       " [0, 1735, 0, 4, 6],\n",
       " [0, 1482, 0, 6, 0],\n",
       " [0, 5114, 0, 6, 0],\n",
       " [0, 256, 0, 6, 0],\n",
       " [0, 19, 0, 6, 0],\n",
       " [0, 877, 0, 6, 1],\n",
       " [0, 272, 0, 6, 0],\n",
       " [0, 853, 0, 6, 0],\n",
       " [0, 177, 0, 6, 0],\n",
       " [0, 1985, 0, 6, 0],\n",
       " [0, 202, 0, 6, 0],\n",
       " [0, 2006, 0, 6, 0],\n",
       " [0, 482, 0, 6, 0],\n",
       " [1, 37403, 8, 1, 8],\n",
       " [1, 9989, 0, 1, 6],\n",
       " [1, 24833, 0, 1, 8],\n",
       " [1, 7674, 7, 1, 3],\n",
       " [1, 34572, 0, 1, 1],\n",
       " [1, 34566, 7, 1, 75],\n",
       " [1, 2167, 0, 1, 1],\n",
       " [1, 40852, 9, 1, 8],\n",
       " [1, 10087, 7, 1, 3],\n",
       " [1, 38680, 0, 1, 1],\n",
       " [1, 40052, 8, 1, 13],\n",
       " [1, 40748, 9, 1, 20],\n",
       " [1, 1604, 0, 1, 24],\n",
       " [1, 20507, 0, 1, 1],\n",
       " [1, 21, 9, 1, 958],\n",
       " [1, 38483, 0, 1, 1],\n",
       " [1, 26243, 7, 1, 1],\n",
       " [1, 42203, 9, 1, 2],\n",
       " [1, 40028, 10, 1, 11],\n",
       " [1, 39551, 0, 1, 1],\n",
       " [1, 39617, 0, 1, 2],\n",
       " [1, 3972, 7, 1, 48],\n",
       " [1, 481, 8, 1, 25],\n",
       " [1, 22199, 7, 2, 24],\n",
       " [1, 6547, 6, 2, 13],\n",
       " [1, 9919, 8, 2, 25]]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = zip(dfw['user_id'], dfw['anime_id'], dfw['rating'], dfw['watching_status'], dfw['watched_episodes'])\n",
    "# anime_watch_data = [[*i] for i in x]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
